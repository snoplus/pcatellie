\documentclass[12pt]{article}
\title{\textbf{TELLIE PCA: \\ Processing automation}}
\date{February 2023}
\author{Michal Rigan}
\usepackage{hyperref}
\hypersetup{
     colorlinks   = true,
     urlcolor = blue,
     citecolor    = grey
}
\hypersetup{colorlinks=true}
\usepackage{graphicx}
\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\footnotesize,
    frame=single, % adds a frame around the code
    xleftmargin=3.4pt,
    xrightmargin=3.4pt,
}
\graphicspath{ {images/} }
\begin{document}

\maketitle{}

\vspace{7cm}
\paragraph{}
This document describes what the TELLIE PCA automation does; why, and how.
\clearpage

\tableofcontents

\clearpage

\section{Why automation}
\paragraph{}
The process of extracting and validating PCA constants from TELLIE data is complex. This piece of software was developed to streamline the process of obtaining the PCA constants, at reasonably high speed. \\
Additionally, it was designed to:
\begin{itemize}
	\item be independent of the method used for Data-taking
	\item be modular, easily modifiable and configurable
	\item require minimal human input
	\item provide monitoring
	\item be mostly standalone
\end{itemize}

\section{Overview}
\paragraph{}
The TELLIE PCA Automation overview is shown in Figure~\ref{fig:overview}.\\There are two main parts: TELLIE \textbf{\texttt{Data-taking}} and \textbf{\texttt{Data-processing}}.

\paragraph{}
Data-taking is done independently of the processing (as the exact method was not yet finalised before developing processing). More information can be found in \href{https://www.snolab.ca/snoplus/private/DocDB/cgi/ShowDocument?docid=7612}{TELLIE Data-taking automation document}. It should be noted that \texttt{Validation \#1} is taken care of by Data-processing.

\paragraph{}
Data-processing is everything that is done with TELLIE PCA data once it is stored. This includes performing checks on the data, making fits required for further processing, generating tables (both local and online), extracting PCA constants, benchmarking these constants, and a suite of monitoring for these steps. These will be described below.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.9\textwidth]{./plots/overview.png}}
  \caption{\centering Overview of the TELLIE PCA Automation.}
  \label{fig:overview}
\end{figure}

\section{Data-taking}
\subsection{Validation \#1}\label{sec:val1}
\paragraph{}
As mentioned above, even though \texttt{Validation \#1} is logistically part of Data-taking, it is performed by Data-processing, and is also independent of the method used to take data.\\
\textbf{Goal:} Validate that the data is of required quality for PCA.

\paragraph{}
Some of the checks performed are: correct fibre, number of events, number of EXTA events, passed hits, cuts on PMTs, checks on LPC, run lenght, frequency, NHit distribution, NHit over time, delays, time of hits over time, number of peaks, PMTs in beamspot, PMT occupancy, PIN, PIN vs NHit, events over subrruns, and more.

\paragraph{}
The corresponding monitoring page will show basic information for this run; data for events, hits, and times; NHit information; PMTs information; Cuts; Flags; and associated plots. The flags are of special importance, as they form a 'bitword'. This bitword is shown in the list page for each fibre for particular dataset.\\
Examples from the monitoring are shown in Figures~\ref{fig:val1}, \ref{fig:val2}, \ref{fig:val3}, \ref{fig:val4}, \ref{fig:val5}, \ref{fig:val6}, \ref{fig:val7}, \ref{fig:val8}, \ref{fig:val9}, \ref{fig:val10}, \ref{fig:val11}, \ref{fig:val12}, \ref{fig:val13}, \ref{fig:val14}, and \ref{fig:val15}.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val1.png}}
  \caption{\centering \texttt{Validation \#1}: General information.\hspace{\textwidth}This is useful to confirm that the expected fibre is being used, the mode of firing is correct, and that the number of subruns is consistent.}
  \label{fig:val1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val2.png}}
  \caption{\centering \texttt{Validation \#1}: Information regarding events, hits, and times.\hspace{\textwidth}Important features: the number of total events should be equal to or more than CouchDB events. CouchDB events should correspond to the number of requested TELLIE events. The number of EXTA events should be close to CouchDB events (some will be lost due to stolen triggers). Most events should pass checks. The percentage of passed hits will be always low ($\sim$25\%) mostly due to the angular cut, defining the beamspot. The peak times should all be very similar (within few ns). Finally, the direct hit time should not change (much) over datasets, as long as we are not chaning the environment (scintillator) anymore.}
  \label{fig:val2}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val3.png}}
  \caption{\centering \texttt{Validation \#1}: NHit information.\hspace{\textwidth}The NHit should be close to the expected value (this was 40-42 for old datasets). There should only be a small variation.}
  \label{fig:val3}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val4.png}}
  \caption{\centering \texttt{Validation \#1}: PMT statistics.\hspace{\textwidth}We should make sure we are hitting PMTs in the beamspot, and that these PMTs have good occupancy (between 1-5\%, as to have high enough statistics above noise to extract the constants, but to avoid being contamined by multiple PE hits).}
  \label{fig:val4}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val5.png}}
  \caption{\centering \texttt{Validation \#1}: Other information, including calculated run length from EXTA events, calculated frequency, and correlation between PIN and NHit.\hspace{\textwidth}We should check the real run length and frequency are as expected (they will be slightly lower than expected, due to missing EXTA triggers).}
  \label{fig:val5}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val6.png}}
  \caption{\centering \texttt{Validation \#1}: Hit statistics, showing the number of hits that were cut, by category.\hspace{\textwidth}Check cuts on hits and PMTs. Should especially look for outliers. The angular cut will always be big, and that is ok, as we only want to use PMTs in the beamspot (other fibres will cover other PMTs, to get the preferred occupancy).}
  \label{fig:val6}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.85\textwidth]{./plots/val7.png}}
  \caption{\centering \texttt{Validation \#1}: Flags. These are the results of checks/tests on a variety of run/hits atributes. The comments should be a reasonable hint to what each check does.}
  \label{fig:val7}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val8.png}}
  \caption{\centering \texttt{Validation \#1}: Plots showing occupancy information.\hspace{\textwidth}We should make sure that there are enough PMTs in the beamspot with the required occupancy ($>$100).}
  \label{fig:val8}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val9.png}}
  \caption{\centering \texttt{Validation \#1}: Plots showing NHit information.\hspace{\textwidth}The NHit distribution should be approximately gaussian, with the peak around the expected value (40-42). The NHit should be stable over time, and there should be no noticeable drop at the start of the run.}
  \label{fig:val9}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val10.png}}
  \caption{\centering \texttt{Validation \#1}: Plots showing hit times information.\hspace{\textwidth}Similar to NHit, we should confirm the peak is around expected value, the times are consistend over events, and there is no high variation with angle.}
  \label{fig:val10}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val11.png}}
  \caption{\centering \texttt{Validation \#1}: Plots showing PIN and NHit information.\hspace{\textwidth}The PIN values should have low variation (within 100s) and there should be no clear trend over subruns. The NHits here are per subrun, therefore the low value. It should be stable over subruns. Finally, there should be positive correlation between the NHit and PIN (mind the range of erros).}
  \label{fig:val11}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val12.png}}
  \caption{\centering \texttt{Validation \#1}: Plots showing delays information.\hspace{\textwidth}Both fibre and trigger delay have to be constant over subruns! Additionally, the trigger delay should be constant across fibres for a dataset. This is essential for the calibration.}
  \label{fig:val12}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val13.png}}
  \caption{\centering \texttt{Validation \#1}: Plots showing data using flatmaps.\hspace{\textwidth}These are to confirm we are getting a beamspot, that the light is there, is not spread out too much, and the occupancy is correct in the beamspot.}
  \label{fig:val13}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val14.png}}
  \caption{\centering \texttt{Validation \#1}: Other information.\hspace{\textwidth}The number of events should be approximately constant over subruns (again, we lose some due to stolen triggers.}
  \label{fig:val14}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val15.png}}
  \caption{\centering \texttt{Validation \#1}: The bitword from \texttt{Validation \#1} shown on the dataset list page for selection of runs.\hspace{\textwidth}The bitword here is made up from the values of flags, corresponding to the checks, for each fibre. Clicking this bitword leads to the \texttt{Validation \#1} page for this run.}
  \label{fig:val15}
\end{figure}

\paragraph{}
The code running \texttt{Validation \#1} is located at:
\begin{lstlisting}
Automation/Processing/validate/TestUser.cc
\end{lstlisting}
This includes the logic for the checks, and generates the bitword. Plots are also made here.

\clearpage

\section{Data-processing}
\subsection{PCA table generation}\label{sec:fits}
\paragraph{}
There are several corrections that need to be fitted for, which are later used for the extraction of PCA constants. The fits need to happen in succession, as the output of one feeds into the next. Between steps, these are stored as text files. After all fits are made, a local table is produced, combining the corrections. This table is loaded by the PCA Processor.\\
\textbf{Goal:} Make fits, obtain corrections required for the extraction of PCA constants. Produce final PCA table.
\paragraph{}
These fits are: beamspot fir, fibre direction, angular systematic, injection time. These are discussed below.

\subsubsection{Fit: beamspot}\label{subsub:bs}
\paragraph{}
First fit to data is the beamspot fit. The idea is to fit PMTs depending on the NHit. PMTs directly opposite the fibre will have the highest NHit, which will drop as the angle (PMT wrt fibre) increases. The method splits PMTs into faces (triangles). It should be mentioned that this could be improved by a dynamic NHit (correcting for offline PMTs and shadows from objects in the way).

\paragraph{}
Please look at Figure~\ref{fig:beamspot} for an example fit. For real data please look at the monitoring section, Section~\ref{sec:monitor}.

\paragraph{}
Code-wise, this is located at :
\begin{lstlisting}
Automation/Processing/postition_fit/TestUser.cc
\end{lstlisting}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.9\textwidth]{./plots/beamspot.png}}
  \caption{\centering \texttt{Fit}: beamspot.\hspace{\textwidth}}
  \label{fig:beamspot}
\end{figure}

\subsubsection{Fit: direction}\label{subsub:dir}
\paragraph{}
Once the beamspot position/center is known, the fibre direction can be extracted. The fibre position as in ratDB is assumed correct (we don't expect this to change), however, the direction (or at least the effective direction) can change, depending on the status of the PMTs (offline, low rate) and objects in the way (belly plates, ropes, filling tubes, etc). Recalculating this direction allows for a better definition of the beamspot, and this leads to better use of the PMTs during the calibration - there are angular cuts on the PMTs later on (as we only want to calibrate the PMTs mostly directly across the fibre - in straight line, without reflections, refractions, and scattering).

\paragraph{}
Please look at Figure~\ref{fig:dir} for an example fit. For real data please look at the monitoring section, Section~\ref{sec:monitor}. 

\paragraph{}
Code-wise, this is located at the same as the beamspot fit (these two fits are done in single instance):
\begin{lstlisting}
Automation/Processing/postition_fit/TestUser.cc
\end{lstlisting}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.9\textwidth]{./plots/dir.png}}
  \caption{\centering \texttt{Fit}: fibre direction.\hspace{\textwidth}}
  \label{fig:dir}
\end{figure}

\paragraph{}
For more on the beamspot and fibre direction fit please look at \href{http://users.sussex.ac.uk/~mr514/TELLIE_fibre_validation.pdf}{TELLIE fibre validation}.

\subsubsection{Fit: angular systematic}\label{subsub:as}
\paragraph{}
The angular systematic is (in this case) a name encapsulating the correction of the effect of modal dispersion for an optical fibre. The light at an angle is injected into the detector at later times, increasing with the angle. This is shown in Figure~\ref{fig:as1}.\\
For this purpose, the PMT residual hit times are fitted for, and the peak hit times for PMTs are plotted as a function of the angle for a fibre. Then, a fit is performed for the data. The fit function is based on a simplified geometric model of a fibre, Figure~\ref{fig:as2}. There are two parameters describing the fit function, ang a and ang b. The ang b parameter is used for time correction in the PCA processor.

\paragraph{}
Small note: because angular systematic fit requires residual hit times, previous PCA calibration data is required.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.9\textwidth]{./plots/as1.png}}
  \caption{\centering \texttt{Fit}: angular systematic.\hspace{\textwidth}The modal effects within the fibre. Light at an angle is injected later into the detector.}
  \label{fig:as1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.9\textwidth]{./plots/as2.png}}
  \caption{\centering \texttt{Fit}: fibre direction.\hspace{\textwidth}The simplified geometric model for light modal effects in an optical fibre.}
  \label{fig:as2}
\end{figure}

\paragraph{}
Code-wise, this is located at:
\begin{lstlisting}
Automation/Processing/angular_systematic/TestUser.cc
\end{lstlisting}

\paragraph{}
For more on the angular systematic effect and the fit please look at \href{http://users.sussex.ac.uk/~mr514/TELLIE_angular_systematic.pdf}{TELLIE fibre validation}.

\subsubsection{Fit: Injection time}\label{subsub:inj}
\paragraph{}
The injection time is the time light leaves the fibre (and enters the detector). This is defined as:
$$ Injection\:time = Hit\:time - Bucket\:time - Angular\:correction $$
This is sometimes called pca offest, and is needed for PCA extraction in the PCA processor. Theme method is to obtain the raw hit times, apply the corrections above, and fit the peak of that distribution, as shown in Figure~\ref{fig:inj}.

\paragraph{}
Code-wise, this is located at:
\begin{lstlisting}
Automation/Processing/pca_offset/TestUser.cc
\end{lstlisting}

\paragraph{}
For more details on bucket time, please look at \href{https://www.snolab.ca/snoplus/private/DocDB/cgi/ShowDocument?docid=3138&version=5}{PMT bucket time}.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/inj.png}}
  \caption{\centering \texttt{Fit}: injetion time.\hspace{\textwidth}The residual hit times are fitted to obtain the injection time (pca offset). Right plot is a zoom over the peak.}
  \label{fig:inj}
\end{figure}

\subsection{Comparing PCA tables}\label{sub:comp_tab}
\textbf{Goal:} Compare the PCA tables (including corrections) for neighbouring datasets. This is useful to monitor stability of the system and to highlight outliers. Also a sense check that the values are in-line with previous sets (nothing went horribly wrong).

\paragraph{}
The code is located at:
\begin{lstlisting}
Automation/Processing/pca_tables/compare_two.py
Automation/Processing/pca_tables/compare_all.py
\end{lstlisting}

\paragraph{}
This creates PCA table plots shown in the monitoring section, Section~\ref{sec:monitor}.

\subsection{Validation \#2}\label{sec:val2}
\paragraph{}
Similar to \texttt{Validation \#1}, \texttt{Validation \#2} runs checks on data. In this case, it loads the corrections from the PCA table including the fits.\\
\textbf{Goal:} Check and confirm that the fits are sensible.

\paragraph{}
Some of the tests included here are: mean, rms, min, and max for each correction; distribution, peak(s), and angular dependence for  the residual times; specific trends, and more. 

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val20.png}}
  \caption{\centering \texttt{Validation \#2}: Information relating to Time-of-Flight.\hspace{\textwidth}The mean should always be physical, and the RMS should not be very high ($>$0.5 ns).}
  \label{fig:val20}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val21.png}}
  \caption{\centering \texttt{Validation \#2}: Information relating to angular systematic fit.\hspace{\textwidth}The mean should never be too high ($>$2 ns).}
  \label{fig:val21}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val22.png}}
  \caption{\centering \texttt{Validation \#2}: Information relating to bucket time.\hspace{\textwidth}The mean should always be (almost) constant ($\sim$0.47 ns) with low RMS. }
  \label{fig:val22}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val23.png}}
  \caption{\centering \texttt{Validation \#2}: Direct and residual hit times.\hspace{\textwidth}There should only be 1 peak for each distribution, and the peak times should be where expected. A straigh line is expected. }
  \label{fig:val23}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val24.png}}
  \caption{\centering \texttt{Validation \#2}: Flags. These are the results of checks/tests on a variety of run/hits atributes. The comments should be a reasonable hint to what each check does.}
  \label{fig:val24}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val25.png}}
  \caption{\centering \texttt{Validation \#2}: Plots showing the distribution of the corrections.\hspace{\textwidth}ToF should be decreasing over angle, peaking around 83~ns and can never be more than 84~ns. The angular systematic correction has to be increasing with the angle. Bucket time should be a narrow distribution around 0.47~ns. }
  \label{fig:val25}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/val26.png}}
  \caption{\centering \texttt{Validation \#2}: Plots showing the angular dependence of hit times, both raw and residual.\hspace{\textwidth}After corrections, the hit times should be mostly independent of the angle. }
  \label{fig:val26}
\end{figure}

\paragraph{}
The corresponding monitoring page will show the fits information for this run, including Flags; and associated plots. The flags are of special importance, as they form a 'bitword'. This bitword is shown in the list page for each fibre for particular dataset.\\
Examples from the monitoring are shown in Figures~\ref{fig:val20}, \ref{fig:val21}, \ref{fig:val22}, \ref{fig:val23}, \ref{fig:val24}, and \ref{fig:val25}.

\paragraph{}
The code running \texttt{Validation \#2} is located at:
\begin{lstlisting}
Automation/Processing/validate2/TestUser.cc
\end{lstlisting}
This includes the logic for the checks, and generates the bitword. Plots are also made here.

\clearpage

\subsection{PCA constants}\label{sub:pca_cons}
\textbf{Goal:} Run the PCA Processor that extract the PCA constants (both timing and charge).

\paragraph{}
This is the main step of the loop. The RAT PCA processor is run over the dataset. It loads the PCA table that cointains the corrections that was created in previous steps. The PCA constants are extracted here and stored as ratdb tables. PCA log files are also created here. 

\paragraph{}
For details on PCA calibration, please read \href{https://www.snolab.ca/snoplus/private/DocDB/cgi/ShowDocument?docid=1987}{PCA calibration with SNO+ RAT}.

\subsection{Benchmarking}\label{sub:bench}
\paragraph{}
This process is used to actually load, use, and compare the PCA constants - cable delays, time-walk fit, and charge fits: threshold, peak, hhp for QHS and QHL.\\
There are two ways to achieve this comparison. One is to purely look at the values of the constants (time and charge) and compare them directly. The other one is to apply the new constants to a run: ie calibrate PMTs with these new constants, and analyse hit times in a well understood run. Usually the latest well understood laserball run is used (117567). Then, a residual hit times distribution is obtained from data.\\
\textbf{Goal:} Compare the set of constants against the closest (previous) set. Useful to see overall stability and for highlighting outliers.

\paragraph{}
As usual, look at the corresponding subsection of the Monitoring section, Section~\ref{sec:monitor}.

\subsection{Monitoring}\label{sec:monitor}
\paragraph{}
This is the most important part for the user. Every step of the system creates logs and plots that are available online on Minard. There are many pages, and everything important (and more) is presented. 
\textbf{Goal:} Provide monitoring of each step of the chain. Also compares fibres and PMTs between datasets.

\paragraph{}
Most parts of the system will be highlighted here. A good rule to using minard portion of the TELLIE PCA processing is that most things are clickable and will lead to detailed page with logs and plots.

\subsubsection{Where}
\paragraph{}
The minard page for TELLIE PCA Processing can be accessed using the main header bar, by slecting the \textbf{PMTcal} tab, and clicking the \textbf{PCA Tellie Processing}, as shown in Figure~\ref{fig:min1}.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.4\textwidth]{./plots/min1.png}}
  \caption{\centering \texttt{Minard}: Location of PCA Tellie Processing button.\hspace{\textwidth}This is inside the PMTcal tab.}
  \label{fig:min1}
\end{figure}

\subsubsection{What}
\paragraph{}
This leads to the \textbf{TELLIE PCA datasets page}. This is the main/overview page for the TELLIE PCA Processing. It shows the list of datasets (Figure~\ref{fig:min2}), the PMT search box (Figure~\ref{fig:min3}), and the list of thresholds (Figure~\ref{fig:min4}).
\paragraph{}
The list of datasets (Figure~\ref{fig:min2}) is the starting point. Again, most cells are clickable and will lead to more detailed page:
\begin{itemize}
	\item Clicking on the cell in 'Run range' will bring an overview page for that particular dataset, Figure~\ref{fig:min8}.
	\item The 'PCA table' cell will show a page comparing the PCA table associated with that dataset to previous PCA table. Figures~\ref{fig:tab1}, \ref{fig:tab2}, \ref{fig:tab3}, and \ref{fig:tab4}.
	\item 'PCA processor' page shows the results of PCA Processor: Figures~\ref{fig:pca1}, \ref{fig:pca2}, \ref{fig:pca3}, \ref{fig:pca4}, \ref{fig:pca5}, and \ref{fig:pca6}.
	\item 'Benchmarking' shows plot comparing the PCA constants obtained in this dataset to previous constant, shown in Figures~\ref{fig:bench1}, \ref{fig:bench2}, \ref{fig:bench3}, \ref{fig:bench4}, \ref{fig:bench5}, \ref{fig:bench6}, and \ref{fig:bench7}.
	\item 'Status' presents information from parsed log file from PCA Processor. It will list warnings or errors from the PCA processor, Figure~\ref{fig:log0}.
	\item 'TW' shows the time-walk information for this set of constants. PMTs with issues such as too high RMS or high Q tail are listed here. See Figures~\ref{fig:log_tw}, \ref{fig:log1}, \ref{fig:log2}, and \ref{fig:log3}.
	\item 'GF' shows the time-walk information for this set of constants. PMTs with issues such as QHS TH too high or Peakfinder found multiple peaks are listed here. Figures~\ref{fig:log_gf}, \ref{fig:log1}, and \ref{fig:log3}.
	\item Additionally, clicking the 'PCA tables' header lead to page comparing PCA tables across all available datasets. Note Figures~\ref{fig:min5}, \ref{fig:min6}, and \ref{fig:min7}.
	\item It is also possible to look at fibre data across datasets (this is perhaps the most interesting feature). One can get here by clicking the fibre name on the dataset page (Figure~\ref{fig:min8}). A selection of plots are shown in Figure~\ref{fig:min9} and Figure~\ref{fig:min10}.
	\item Finally, there are plots for PMTs for each dataset (Figure~\ref{fig:pmt1} and Figure~\ref{fig:pmt2}) and over datasets (using PMT search, Figure~\ref{fig:min3}).
\end{itemize}

\clearpage

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/min2.png}}
  \caption{\centering \texttt{Minard}: The main table of the main page.\hspace{\textwidth}This table holds a line for each processed dataset. Most cells in here are clickable, leading to a more detailed page or list. These get auto-populated with the processing suite.}
  \label{fig:min2}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/min3.png}}
  \caption{\centering \texttt{Minard}: PMT search section.\hspace{\textwidth}One can input a PMT number and a detailed page showing the PMT cable delays over all datasets will be shown.}
  \label{fig:min3}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/min4.png}}
  \caption{\centering \texttt{Minard}: Limits section.\hspace{\textwidth}This section lists the environment thresholds (used for validation checks).}
  \label{fig:min4}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/min8.png}}
  \caption{\centering \texttt{Minard}: A list for TELLIE PCA dataset.\hspace{\textwidth}. This table shows the bitwords for both validations (see Section~\ref{sec:val1} and Section~\ref{sec:val2}) and results of main fitting parameters (angular b and injection time, see Section~\ref{sec:fits}). Clicking a cell brings up more detailed page with data and plots. One can also click on the fibre name, which shows data for that fibre across all datasets.}
  \label{fig:min8}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/tab1.png}}
  \caption{\centering \texttt{Minard}: PCA table for one dataset.\hspace{\textwidth}This serves as a comparison of a single dataset's PCA table to the closest previous dataset's PCA table. These plots: IPW, IPW difference.}
  \label{fig:tab1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/tab2.png}}
  \caption{\centering \texttt{Minard}: PCA table for one dataset.\hspace{\textwidth}This serves as a comparison of a single dataset's PCA table to the closest previous dataset's PCA table. These plots: PCA offset (also called injection time), PCA offset difference.}
  \label{fig:tab2}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/tab3.png}}
  \caption{\centering \texttt{Minard}: PCA table for one dataset.\hspace{\textwidth}This serves as a comparison of a single dataset's PCA table to the closest previous dataset's PCA table. These plots: Angular b parameter, angular b parameter difference.}
  \label{fig:tab3}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/tab4.png}}
  \caption{\centering \texttt{Minard}: PCA table for one dataset.\hspace{\textwidth}This serves as a comparison of a single dataset's PCA table to the closest previous dataset's PCA table. These plots: fitted direction.}
  \label{fig:tab4}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pca1.png}}
  \caption{\centering \texttt{PCA Processor}: Hit coverage (hits per PMT), Offline PMTs (purple means offline), PCA hits per PMT (hits passing cuts), PCA TW RMS, PCA intersec.\hspace{\textwidth}}
  \label{fig:pca1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pca2.png}}
  \caption{\centering \texttt{PCA Processor}: Cable delays.\hspace{\textwidth}Cable delay per LCN (logical channel number), Cable delays across cards, the difference of this and previous cable delay per LCN, and the difference of this and previous cable delay - histogram. }
  \label{fig:pca2}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pca3.png}}
  \caption{\centering \texttt{PCA Processor}: LED data.\hspace{\textwidth}LED coverage (\# LEDs hitting a PMT), Best fibre (the fibre with highest occupancy (within limits) used for calibration), LED offsets (respective time offset between LEDs), fibre delay (the difference of current and previous LED offset).}
  \label{fig:pca3}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pca4.png}}
  \caption{\centering \texttt{PCA Processor}: Charge data.\hspace{\textwidth}The value of threshold, HHP (high half point), and peak for both QHS (left) and QHL (right).}
  \label{fig:pca4}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pca5.png}}
  \caption{\centering \texttt{PCA Processor}: QHS charge data.\hspace{\textwidth}This time showing the previously mentioned charge values as a difference of newly measured and latest value.}
  \label{fig:pca5}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pca6.png}}
  \caption{\centering \texttt{PCA Processor}: QHL charge data \#2.\hspace{\textwidth}This time showing the previously mentioned charge values as a difference of newly measured and latest value.}
  \label{fig:pca6}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/bench1.png}}
  \caption{\centering \texttt{Benchmarking}: General section.\hspace{\textwidth}This summarizes basic benchmarking data such as: run numbers (starting number of the set), \# of offline PMTs for each set, PMTs with zero and low occupancy, and successfully calibrated PMTs.}
  \label{fig:bench1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.81\textwidth]{./plots/bench2.png}}
  \caption{\centering \texttt{Benchmarking}: Cable delays data.\hspace{\textwidth}This section shows cable delays data for PMTs. Outliers are PMTs with new cable delay value very different to previous. PMTs that are now calibrated that were not before are shown (can be clicked, showing the actual PMT data), as well as PMTs that were previously calibrated but couldn't be in this set.}
  \label{fig:bench2}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/bench3.png}}
  \caption{\centering \texttt{Benchmarking}: Time-walk data.\hspace{\textwidth}This is hopefully self-explanatory (see notes in the table).}
  \label{fig:bench3}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.95\textwidth]{./plots/bench4.png}}
  \caption{\centering \texttt{Benchmarking}: Plots for cable delays.\hspace{\textwidth}Showing the cable delays for this (left) and previous (right) calibration. Difference at the bottom.}
  \label{fig:bench4}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/bench5.png}}
  \caption{\centering \texttt{Benchmarking}: Flat map plots.\hspace{\textwidth}Top: flat maps showing the cable delays for this (left) and previous (right) set. Bottom: the difference of the cable delays between this and previous set (left); zoomed view of left plot (right).}
  \label{fig:bench5}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/bench6.png}}
  \caption{\centering \texttt{Benchmarking}: Time-walk plots.\hspace{\textwidth}The difference between this and previous set: TW gradient (left) and TW intercept (right).}
  \label{fig:bench6}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/bench7.png}}
  \caption{\centering \texttt{Benchmarking}: Peak fit plots.\hspace{\textwidth}These plots shown the residual hit times from a test laserball run, with the newly obtained, and old (previous set) cable delays applied to the PMT timings, respectively. Due to the difference of the actual number of PMTs that were calibrated, there will be difference. What is important is to look at the peak of this distribution (right plot).}
  \label{fig:bench7}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/log0.png}}
  \caption{\centering \texttt{PCA logs}: Status.\hspace{\textwidth}This is data parsed from the PCA processor main log file. It lists bits that failed.}
  \label{fig:log0}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/log_gf.png}}
  \caption{\centering \texttt{PCA logs}: Gain fit.\hspace{\textwidth}This is data parsed from the PCA processor GF log file. It lists PMTs that failed particular checks, by group. The groups can be expanded, showing crate maps highlighting the PMTs in question.}
  \label{fig:log_gf}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/log_tw.png}}
  \caption{\centering \texttt{PCA logs}: Time-walk fit.\hspace{\textwidth}This is data parsed from the PCA processor TW log file. It lists PMTs that failed particular checks, by group. The groups can be expanded, showing crate maps highlighting the PMTs in question.}
  \label{fig:log_tw}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/log1.png}}
  \caption{\centering \texttt{PCA logs}: Example crate map.\hspace{\textwidth}This is an example crate map highlighting PMTs that failed the low occupancy check. Same map is available for each check where PMTs that failed exist. The maps are shown by clicking the 'Show/Hide' button.}
  \label{fig:log1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/log2.png}}
  \caption{\centering \texttt{PCA logs}: Example check detailed page.\hspace{\textwidth}After clicking any of the checks on the log pages, a detailed page for the check is shown. This shows the crate map and lists the offending PMTs. Each PMT can be clicked again for more detailed page for that PMT.}
  \label{fig:log2}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.9\textwidth]{./plots/log3.png}}
  \caption{\centering \texttt{PCA logs}: PMT page.\hspace{\textwidth}After a PMT is selected on one of the check pages, its status for that particular calibration is shown. Plots for time and charge fits are displayed alongside the status words for this PMT.}
  \label{fig:log3}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/min5.png}}
  \caption{\centering \texttt{PCA tables}: Comparing the PCA tables across all available datasets.\hspace{\textwidth}IPW (internal pulse width) parameter shown.}
  \label{fig:min5}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/min6.png}}
  \caption{\centering \texttt{PCA tables}: Comparing the PCA tables across all available datasets.\hspace{\textwidth}PCA offset (injection time) shown. Relative version on the bottom.}
  \label{fig:min6}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/min7.png}}
  \caption{\centering \texttt{PCA tables}: Comparing the PCA tables across all available datasets.\hspace{\textwidth}The angular b parameter from angular systematic study.}
  \label{fig:min7}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.85\textwidth]{./plots/min9.png}}
  \caption{\centering \texttt{Fibre data across datasets}: Angular systematic fit.\hspace{\textwidth}Clicking a fibre name in the table for a dataset brings a page displaying data for this fibre across all available datasets. Example for ang b parameter shown.}
  \label{fig:min9}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.85\textwidth]{./plots/min10.png}}
  \caption{\centering \texttt{Fibre data across datasets}: Residual hit times.\hspace{\textwidth}licking a fibre name in the table for a dataset brings a page displaying data for this fibre across all available datasets. Example for residual hit times shown.}
  \label{fig:min10}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pmt1.png}}
  \caption{\centering \texttt{PMT plots}: teca, TW, charges.\hspace{\textwidth}Selecting a PMT from the PCA log section or benchmarking will show its current calibration data compared to previous dataset. This includes Teca, TW, QHS, and QHL.}
  \label{fig:pmt1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/pmt2.png}}
  \caption{\centering \texttt{PMT plots}: cable delay.\hspace{\textwidth}electing a PMT from the PCA log section or benchmarking will show its current calibration data compared to previous dataset. This includes cable delays.}
  \label{fig:pmt2}
\end{figure}

\clearpage

\section{System}
\paragraph{}
This section will describe some of the features of the overall processing.

\subsection{Simple}\label{subsec:simple}
\paragraph{}
The system is based on being very simple and with minimum human input. As it stands, it only needs to be started, providing a single text file with runs corresponding to a dataset.\\
Example runlist text file:
\begin{lstlisting}
300165
300167
300372
300171
300173
...
\end{lstlisting}

\subsection{Modular}
\paragraph{}
The whole system is a network of multiple individual steps, managed by one master script. The master script spawns subprocessed. Individual steps can be (re)run. Modules can be easily modified, separately.

\subsection{Submission platform}
\paragraph{}
To process the whole dataset, many individual jobs need to be run. There are 6 steps for each run: \texttt{Validation \#1}, \texttt{position fit}, \texttt{angular systematic fit}, \texttt{injection fit}; and addition steps to be run per dataset: \texttt{PCA Processor}. There are several other global jobs: creating PCA table, comparing PCA tables, checking PCA output, comparing time-walk data, benchmarking (multiple steps), final compare scripts (multiple). For a single set of 95 runs (one per fibre), this ends up totalling close to 600 (95*6 + global + other) individual processes.

\paragraph{}
To deal with this, the master scripts has inbuilt submission platform. It spaws child processes (up to a configurable limit) and monitors their status. There is a queue that holds jobs to be submitted. The whole system is run in steps, as usually consecutive steps require the output of previous steps. 

\paragraph{}
If processes fail, they are retried up to a limit. After that, the failed processes need to be investiaged and rerun manually (if needed).

\subsection{Customizable}
\paragraph{}
The checks in validation steps are often based on threshold values. There are loaded from environment and should be tuned before running. There are comments explaining what the threshold values are, please see Figure~\ref{fig:thresh}.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.1\textwidth]{./plots/thresh.png}}
  \caption{\centering The threshold parameters, used for validation. These can be tuned as required.}
  \label{fig:thresh}
\end{figure}

\subsection{Linked}
\paragraph{}
The processing system is linked to multiple databases. The CouchDB holds data on: belly plates, benchmarking, environment constants, list of fibres, runlists, and document for each run/fit combination. An overview of views in the CouchDB is shown in Figure~\ref{fig:couch}, while an example environment CouchDB document is shown in Figure~\ref{fig:couchdoc}.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.5\textwidth]{./plots/couch.png}}
  \caption{\centering \texttt{CouchDB}: An overview of views in CouchDB database.}
  \label{fig:couch}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.32\textwidth]{./plots/couchdoc.png}}
  \caption{\centering \texttt{CouchDB}: An example CouchDB document (in this case holding the thresholds for checks.}
  \label{fig:couchdoc}
\end{figure}

\paragraph{}
Additionally, the system requires access to ratDB. Finally, there is a plethora of plots created. These need to be linked to minard, usually via nfs mount over network.

\subsection{Regulation}
\paragraph{}
The system was developped to have unified cuts, event selection, checks, and ranges.

\subsection{Evaluative}
\paragraph{}
There are bitwords used in \texttt{Validation \#1} and \texttt{Validation \#2}. There are a proxy for the quality of the data. If tuned correctly, these could be used to ignore specific runs, however, this is not currently implemented.

\clearpage

\section{Code}
\paragraph{}
This section will provide some comments on the code (TELLIE Automation repository).

\subsection{Structure}
\begin{itemize}
	\item \textbf{Data-taking}: This folder holds documents, notes, and early attempts on the data-taking automation (no actual repository for automated TELLIE PCA data-taking!).
	\item \textbf{Doc}: This folder holds documentation (including this doc), reports, and notes on the automated TELLIE PCA processing. Please have a look at this.
	\item \textbf{Processing}: This contains the actual code performing the automated TELLIE PCA processing.
	\begin{itemize}
		\item \textit{angular\_systematic}: Processor for the angular systematic fit, see Subsection~\ref{subsub:as}.
		\item \textit{benchmark}: Scripts to extract comparison plots after benchmarking, see Subsection~\ref{sub:bench}.
		\item \textit{checkPCA}: Scripts to extract plots from the output of PCA processor, see Subsection~\ref{sub:pca_cons}.
		\item \textit{fits}: This holds text files with the results of the fit processors: direction, ang sys, and pca offset.
		\item \textit{minard}: Plots for minard monitoring are stored here. See Subsection~\ref{sec:monitor}.
		\item \textit{pca\_constants}: Holds output ratDB and log files from the PCA processor, Subsection~\ref{sub:pca_cons}.
		\item \textit{pca\_offset}: Processor for the pca offset (injection time) fit, see Subsection~\ref{subsub:inj}.
		\item \textit{pca\_tables}: Scripts to compare PCA tables. Also holds copies of PCA tables. See Subsection~\ref{sub:comp_tab}.
		\item \textit{postition\_fit}: Processor for the position (beamspot) and direction fit, see Subsection~\ref{subsub:bs} and Subsection~\ref{subsub:dir}.
		\item \textit{runtime}: A folder to hold temporary files while processing a dataset.
		\item \textit{scripts}: Other useful scripts, usually called by the master script.
		\begin{itemize}
			\item create\_bench\_apply\_mac.py: Creates RAT macro to run benchmarking - loads the new constants and applies on laserball run.
			\item create\_pca\_proc\_mac.py: Creates RAT macro to run PCA processor for given dataset.
			\item delete\_old\_couchdb.py: Helper script to delete CouchDB documents by type.
			\item get\_belly\_fibres.py: Helper script to create ratDB file containing the list of fibres affected by belly plates (loaded from CouchDB document).
			\item load\_db.py: Helper script to load default fibre directions from ratDB.
			\item make\_ratdb\_table.py: Creates ratDB table from PCA table. This is loaded by the PCA processor to apply corrections to hit times.
			\item master.py: The brain of operations. See Subsection~\ref{sub:master}.
			\item upload\_bench.py: Parses data from benchmark comparison scripts and uploads a CouchDB document.
			\item upload\_env.py: Parses the environment variables and uploads a CouchDB document.
			\item upload\_fits.py: Parses the data from fits and uploads a CouchDB document.
			\item upload\_radtb.py: Uploads ratDB table to postgres. 
			\item upload\_val1.py: Parses the data from \texttt{Validation \#1} step and uploads a CouchDB document.
			\item upload\_val2.py: Parses the data from \texttt{Validation \#2} step and uploads a CouchDB document.
		\end{itemize}
		\item \textit{validate}: Processor to perform the \texttt{Validation \#1} step of the processing suite.
		\item \textit{validate2}: Processor to perform the \texttt{Validation \#2} step of the processing suite.
	\end{itemize}
\end{itemize}

\clearpage

\subsection{Master script}\label{sub:master}
\paragraph{}
This is the main script of the whole suite. This is the one called by the user to start the processing. It handles almost every portion of the suite.

\paragraph{}
The master script requires the run list, in the form of a text file, holding the run numbers for the TELLIE runs forming the dataset. It has inbuilt submission platform, and it will spawn processes to automatically run the TELLIE processing. This is done in specific order, as often consecutive steps require the output of previous step(s). The platform also monitors the output of the processes, and retries them (up to a limit).

\paragraph{}
Here are the steps, in order:
\begin{itemize}
	\item \textit{loads environment}: The environment holds script names and locations.
	\item \textit{parse arguments}: Parses the supplied command line arguments (see Section~\ref{sec:run}).
	\item \textit{upload environment (opt)}: Uploads the environment variables to CouchDB.  
	\item \textit{parse runlist}: Parses the provided runlist (from text file). 
	\item \textit{create dataset}: Uploads a document holding dataset information. 
	\item \textit{check data exists}: Checks that physical files exist for the provided runlist. 
	\item \textit{set job limit}: Sets a limit on how many processes can be run at each time. 
	\item \textit{sort runs}: Order runlist. 
	\item \textit{call Validation \#1}: Runs the \texttt{Validation \#1} step over all runs, using the submission platform. 
	\item \textit{upload Validation \#1}: Uploads the results of \texttt{Validation \#1} to CouchDB.
	\item \textit{call position fit}: Runs the position and direction fit step over all runs, using the submission platform. 
	\item \textit{call ang sys fit}: Runs the angular systematic fit step over all runs, using the submission platform. 
	\item \textit{call pca offset fit}: Runs the pca offset fit step over all runs, using the submission platform. 
	\item \textit{upload fits}: Uploads the results of fit steps (together) to CouchDB.
	\item \textit{call Validation \#2}: Runs the \texttt{Validation \#2} step over all runs, using the submission platform. 
	\item \textit{upload Validation \#2}: Uploads the results of \texttt{Validation \#2} to CouchDB.
	\item \textit{log cleanup}: Removes (now obsolete) logs.
	\item \textit{create run folders}: Create folders for each run in the designated minard location. 
	\item \textit{move plots}: Move plots (created by previous stages) to the minard location.
	\item \textit{make pca table}: Create PCA table from the fit logs.
	\item \textit{move fits}: Move the fit (text) files to their location. 
	\item \textit{compare tables two}: Call script to compare new PCA table to previous one.
	\item \textit{compare tables all}: Call script to recreate plots comparing all PCA tables.
	\item \textit{upload ratdb table}: Call script to upload ratdb table to postgres.
	\item \textit{set new names}: Pre-set names for files (to expect) from PCA processor.
	\item \textit{create pca proc mac}: Call script to create PCA processor RAT macro.
	\item \textit{call pca proc}: Spawn RAT process to run the PCA processor.
	\item \textit{get global offset}: Retrieve the global offset from the PCA log file.
	\item \textit{move pca const}: Move the output files from the PCA processor.
	\item \textit{call checkPCA}: Call scripts to compare the PCA results to previous set.
	\item \textit{call compareTW}: Call scripts to compare TW results to previous set.
	\item \textit{move pca plots}: Move plots created by scripts above to minard location.
	\item \textit{create bench apply mac}: Call script to create benchmarking RAT macro.
	\item \textit{setup tw tables}: This function prepares the TW and GF ratdb tables. These need to be temporarily modified to overwrite the defauls from the ratDB.
	\item \textit{call bench apply}: Spawn RAT process to run the benchmarking.
	\item \textit{call cd compare}: Call script to compare cable delays from benchmarking.
	\item \textit{call tw compare}: Call script to compare time-walk data from benchmarking.
	\item \textit{call peak compare}: Call script to compare residual times peaks from benchmarking.
	\item \textit{upload bench}: Uploads the results of benchmarking steps (together) to CouchDB.
	\item \textit{move bench plots}: Move plots created by scripts above to minard location.
	\item \textit{move bench root}: Move the benchmarking root files to their defined location.
	\item \textit{move pca to minard}: Move PCA ratDBs to minard location (these are needed for online monitoring).
	\item \textit{cleanup}: Move logs (from fits, PCA processor, and benchmarking), and remove (now obsolete) mac, and ratdb files.
	\item \textit{log cleanup}: Remove unwanted logs (from RAT).
	\item \textit{get final job count}: Print out the final job statistics (running, succesful, failed).
\end{itemize}

\paragraph{}
There are several other helper functions that are not called directly, but rather called from within other functions. This includes the submission platform and monitorin. For these, please look at the master script.\\
The script is here:
\begin{lstlisting}
Automation/Processing/scripts/master.py
\end{lstlisting}

\clearpage

\subsection{Cuts and checks}
\paragraph{}
This subsection lists some of the more important cuts and checks that are applied throught the many steps of the processing automation. Please see Figures~\ref{fig:ch1}, \ref{fig:ch2}, \ref{fig:ch4}, and~\ref{fig:ch1}.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=0.85\textwidth]{./plots/ch1.png}}
  \caption{\centering \texttt{Checks}: trigger type.\hspace{\textwidth}The trigger type check to only use events with EXT bit.}
  \label{fig:ch1}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1\textwidth]{./plots/ch2.png}}
  \caption{\centering \texttt{Checks}: PMT checks.\hspace{\textwidth}This highlights the checks on the PMT status, type, PCA \& ECA bitwords, X-talk, PMT position, and more.}
  \label{fig:ch2}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1\textwidth]{./plots/ch4.png}}
  \caption{\centering \texttt{Checks}: LPC features.\hspace{\textwidth}Checks on LPC related features such as the total internal reflection, validity of the path, and the locality.}
  \label{fig:ch4}
\end{figure}

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1\textwidth]{./plots/ch5.png}}
  \caption{\centering \texttt{Checks}: LPC values.\hspace{\textwidth}Additional checks on the actual LPC values to ensure only direct, unreflected, physical paths are used.}
  \label{fig:ch5}
\end{figure}

\clearpage

\section{Deploying}\label{sec:dep}

\subsection{Requirements}
%rat, python+modules,

\subsection{External}
%couchdb (+views +default docs +users/access), ratdb, minard mount

\subsection{Setting up}
%repo + empty folders, env + scons processors, make script folders

\section{Running}\label{sec:run}
\paragraph{}
In general, the running is supposed to be autonomous - after being started. However, I suggest monitoring the application thoroughly the first few times it is run (as the development was done with different setup). It should also be monitored occasionally when tuned, as there will be indications if things go wrong - such as high number of jobs failing. 

\paragraph{}
For actual start-up, I recommend running this in screen. Firstly, the environment needs to be sourced. The \texttt{env.sh} file contains: CouchDB address and credentials, threshold parameters for checks, names and locations of script files, and ratDB credentials. This file is not included with the repository, but is placed in the deployed location manually.

\paragraph{}
Several folders and default files need to be in place for the application to run succesfully. These are mentioned in Section~\ref{sec:dep}.

\paragraph{}
The only input required is the text file holding the run numbers for TELLIE PCA runs (one for each fibre). An example of this is shown in Subsection~\ref{subsec:simple}.

\paragraph{}
Finally, one just calls the master script. There are few command line arguments that can be provided, as shown in Figure~\ref{fig:args}. The only required argument is `-f`, providing the path to the runlist tex file. Other options of interest are `-c`, selecting the number of cores: this corresponds to the number of simultaneous jobs that can be spawned; and '-e', which is an option to reupload the environment. All other arguments allow to select which steps to run from the full suite. In normal conditions - running processing on full TELLIE PCA dataset - it is always recommended to run all steps.

\paragraph{}
An example run procedure:
\begin{lstlisting}
screen -S tellie_pca
cd <Automation repository>
source env.sh
cd runtime
python ../scripts/master.py -f <path/to/runlist.txt> -c <cores>
\end{lstlisting}
Then one can detach from the screen, and attach occassionaly to monitor.

\begin{figure}
\centering
\noindent\makebox[1\textwidth]{
  \includegraphics[width=1.25\textwidth]{./plots/args.png}}
  \caption{\centering \texttt{Master script}: The available command line arguments.}
  \label{fig:args}
\end{figure}

\clearpage

\section{ToDos}
\paragraph{}
This section briefly lists some open questions:
\begin{itemize}
	\item \textit{RAT integration}: the code currently consist of custom user processors. These could all be made official part of RAT once finalised. Same goes for the PCA processor, which is currenly a heavily modified version.
	\item \textit{Data-taking modes}: \href{https://www.snolab.ca/snoplus/private/DocDB/cgi/ShowDocument?docid=7612}{\#7612}
	\item \textit{Tagging events outside Orca}: if one decides for continuous calibration, TELLIE is run 'alongside' ORCA. EXTA events need to be tagged externally, so that they can be extracted from data offline.
	\item \textit{Ensure recent ECA}: recent ECA is essential for PCA calibration. This should be enforced just before running PCA.
	\item \textit{When (from) to apply new PCA constants}: Depending on the data-taking mode, it can take days to weeks to collect enough data for PCA calibration. PCA constants can only be extracted from a full dataset. Once this is done one needs to decide whether to apply the constants from (i) the start of the set, (ii) the end of the set or, (iii) some other time (like middle of the set).
	\item \textit{RatDB tables cache}: because we process every run multiple times (over multiple processors), the ratDB tables are loaded multiple times. In some cases (like ECA tables), this is significant size, and we also have to account for the number of consecutive ratDB connections, which sometimes causes issues (time out). One improvement would be to pre-load the tables and keep them locally while the runs are being processed. 
\end{itemize}

\section{Other documentation}
\paragraph{}
Other useful TELLIE / PCA documentation:
\begin{itemize}
	\item \href{https://www.snolab.ca/snoplus/private/DocDB/cgi/ShowDocument?docid=1987}{PCA calibration with SNO+ RAT}
	\item \href{https://www.snolab.ca/snoplus/private/DocDB/cgi/ShowDocument?docid=4486&version=1}{TELLIE hardware manual}
	\item \href{http://users.sussex.ac.uk/~mr514/TELLIE_Usersmanual.pdf}{TELLIE user manual}
	\item \href{http://users.sussex.ac.uk/~mr514/TELLIE_angular_systematic.pdf}{TELLIE angular systematic study}
	\item \href{http://users.sussex.ac.uk/~mr514/TELLIE_debugging_manual.pdf}{TELLIE debugging}
	\item \href{http://users.sussex.ac.uk/~mr514/TELLIE_fibre_validation.pdf}{TELLIE fibre validation}
	\item \href{https://www.snolab.ca/snoplus/private/DocDB/cgi/ShowDocument?docid=7192}{Michal's thesis}
	\item Also look at the documentation folder in the repository:
	\begin{lstlisting}
	Automation/Doc
	\end{lstlisting}
\end{itemize}

\end{document}
